<!doctype html>
<html lang="en">
  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <meta name="description" content="Stealing and Attacking Production Machine Translation Systems">
    <meta name="author" content="">
    <link rel="icon" href="stealing_blog_images/adversarial2.ico">

    <title>Stealing + Attacking MT</title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.2/css/bootstrap.min.css"
          integrity="sha384-Smlep5jCw/wG7hdkwQ/Z5nLIefveQRIY9nfy6xoR1uRYBtpZgI6339F5dgvm/e9B" crossorigin="anonymous">
    <link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

    <style>
        /* Show it is fixed to the top */
      
      .aligncenter {
        text-align: center;
      }
        body {
          padding-top: 4.5rem;
          position: relative;
          font-size: 1.0rem;          
        }
        h1 {
          width: max-content;
        }
        .anchor-target:target::before {
          display: block;
          content: " ";
          margin-top: -60px;
          padding-top: 60px;
          visibility: hidden;
          pointer-events: none;          
        }
      /*https://stackoverflow.com/questions/35647044/boostrap-how-to-stick-a-button-over-an-image-when-re-sizing*/
        .img-wrapper {
          position: relative;
         }
        .img-overlay {
          position: absolute;
          top: 0;
          bottom: 0;
          left: 0;
          right: 0;
          text-align: left;
        }
        .img-overlay:before {
          content: ' ';
          display: block;
          /* adjust 'height' to position overlay content vertically */
          height: 40%;          
        }
        .jumbotron {
          margin-bottom: .5rem;
          padding: 2rem 2rem;
        }
        .headshot {
          width: 12.5rem;
          margin: 0.85rem;
        }
        .card-body {
          padding: 0.5rem;
        }
        .citation {
          display: block;
          padding: 9.5px;
          margin: 0 0 10px;
          font-size: 13px;
          line-height: 1.42857143;
          word-break: break-all;
          word-wrap: break-word;
          color: #333;
          background-color: #f5f5f5;
          border: 1px solid #ccc;
          border-radius: 4px;
        }
        .answerbutton {
          white-space:normal !important;
          word-wrap: break-word;
          text-align: left;
        }
    
        .box-shadow { box-shadow: 0 .25rem .75rem rgba(0, 0, 0, .05); }
        .fig-shadow { box-shadow: 0 .25rem .75rem rgba(0, 0, 0, .15); }
        .navbar-brand {
          font-family: 'jdfont', cursive;
          font-size:1.5rem;
        }
    
  }
                
    </style>
  </head>
  <body data-spy="scroll" data-target="#navbarCollapse" data-offset="200" style="background-color:#fff">  

    <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
      <a class="navbar-brand" href="#">Stealing + Attacking</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarCollapse">
        <ul class="navbar-nav mr-auto">
          <li>
            <a class="nav-link" href="https://www.ericswallace.com/">Homepage</a>
          </li>          
        </ul>
      </div>
    </nav>

<main role="main" class="container"">
    <div style="margin-top: 2rem;"><h1>Stealing and Attacking Production MT Systems</h1>  </div>    
    <div>            
      <a class="btn btn-lg btn-warning" href="TODO" target="_blank" role="button">Paper &raquo; <i class="fas fa-file-pdf"></i></a>
      <a class="btn btn-lg btn-secondary" href="https://github.com/Eric-Wallace/adversarial-mt" target="_blank" role="button">Code &raquo;</a>
      <a class="btn btn-lg btn-info" href="TODO" target="_blank" role="button">Twitter &raquo;</a>
                                                                                                                             
      <br>
    <br>
    <h3 id="blog" class="anchor-target">Background</h3>
    <p> Many production machine learning systems are served as APIs. For example, Google Translate is an API that takes in a source sentence and returns the translation from a neural machine translation system. ML APIs are lucrative assets for organizations and are typically the result of considerable investments into data annotation and model training. Consequently, the internals of the API are kept hidden to protect intellectual property and system integrity.</p>
                                       

    <h3 id="blog" class="anchor-target">Overview</h3>                                   
    <p> We show how an adversary can <i>steal</i> and <i>attack</i> black-box machine translation (MT) systems. <a href="https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_tramer.pdf" target="_blank">Stealing</a> 
 <a href="https://arxiv.org/abs/1910.12366" target="_blank">a</a> <a href="https://arxiv.org/abs/1602.02697" target="_blank">model</a> allows an adversary to avoid long-term API costs or even launch their own competitor MT service. Attacking a model by creating <i>adversarial examples</i> can expose egregious model predictions that can harm system owners or users.</p>
    <p> The figure below summarizes our work with English→German as an example. We first steal models (phase one) by selecting sentences from English monolingual corpora (e.g., Wikipedia, News), labeling them using the victim API, and then training an <i>imitation model</i> on the resulting data. In phase two, we generate adversarial examples against our imitation model and transfer them to the production systems. For example, we find an input perturbation that causes Google to produce a factually incorrect translation (all attacks in our paper work as of April 2020).</p>
    <p class="aligncenter">
        <img class="card-img-top" src="stealing_blog_images/overview.png" align="middle" style="width:85%">
    </p>
    
    <br><h3> Stealing Production MT Systems </h3>
    <p>We first steal production models by training imitation models as described above. Our method is related to <a href="https://arxiv.org/abs/1503.02531" target="_blank">knowledge distillation</a>: training a student model to imitate the predictions of a teacher. The most important difference from distillation is that the victim’s (i.e., teacher’s) training data is unknown. This causes the queries to typically be <i>out-of-domain</i> for the victim.</p>
    
    <br><h4> <i>Simulated Stealing Experiments </i></h4>
    <p><b>Setup:</b> As a warmup, we first analyze model stealing with simulated experiments. We train a local victim model, query it, and then train imitation models to mimic its outputs. We train imitation models that are different from the victim in various aspects: input dataset, BPE vocabulary, model architecture, and combinations of these differences.</p>
    <p><b>Results: </b> Imitation models can closely match the performance of the victim when the architectures are different. For example, a convolutional seq2seq imitation model reaches similar BLEU scores to a transformer victim model on both in- and out-of-domain test sets.</p>
    <p> Modeling stealing is also possible when the input dataset is different. In particular, we train the victim model on data from TED talks and query it using sentences from the European Parliament. The victim model often produces incorrect or ungrammatical translations for these sentences because they are out-of-domain. Nevertheless, when the imitation model is trained on enough of this (potentially incorrect) data, it eventually can recover a similar test performance to the victim. The green curve in the figure below shows the learning curve of training on normal MT data; the purple curve shows training on the out-of-domain Europarl data that is labeled by the victim.</p>
    <p class="aligncenter">
        <img class="card-img-top" src="stealing_blog_images/data_efficiency.png" align="middle" style="width:45%">
    </p>
                                                                                                                 <p>Interestingly, when the queries are in-domain, there are cases when the imitation model learns faster than the victim (orange curve above). In other words, stolen data can be <i>more useful</i> than professionally-curated MT data. This is likely due to the outputs of the victim model being simpler than human translations, <a href="https://arxiv.org/abs/1911.02727" target="_blank">which eases learning</a>.</p>
    <p>Overall, our results show that model stealing is easy: despite mismatched models and data, imitation models closely imitate their victims.</p>


    <br><h4> <i>Real-World Stealing Experiments </i></h4>
    <p> <b>Evaluating Production Models:</b> We next steal five production MT systems: Google Translate, Bing Translator, DeepL Translator, SYSTRAN Translate, and Yandex Translate. We use English→German and Nepali→English language pairs. We begin by testing the MT services on these languages to provide a point of comparison for our imitation models. The production systems are very strong for English→German: Google, Bing, and DeepL are better than any public model that does not use data outside of WMT14 (e.g., backtranslation data). For Nepali→English, Google achieves 22.1 BLEU which crushes the 15.1 BLEU achieved by the best public model. This gap comes from Google’s internal investments, e.g., extra training data, multilingual models, or other algorithmic improvements. </p>
    <p><b>Stealing Results:</b> We then collect training data for our imitation models by querying the production systems with about 5 million sentences for English→German and 2 million sentences for Nepali→English. Finally, we train transformer MT models on this data. These models closely match the performance of the production systems: they are always within 0.6 BLEU for English→German (table below). For Nepali→English, our system reaches 22.0 BLEU, which nearly matches Google's performance and is 6.9 points ahead of the best public system.</p>
    <p class="aligncenter">
        <img class="card-img-top" src="stealing_blog_images/stealing_numbers.png" align="middle" style="width:50%">
    </p>
    <p>Most worryingly, we estimate that adversaries can recreate our English→German queries for as little as $10 by scraping data from the public demos. Given the upside of obtaining high-quality MT systems, these costs are frighteningly low &#9785;.</p>

    
    <br><h3> Attacking Production MT Systems </h3>
    <p> The second phase of our paper studies adversarial examples. For MT, adversaial attacks can expose errors which cause public and corporate harm. For example, a person was arrested when their Arabic Facebook post meaning "good morning" was mistranslated as "<a href="https://www.theguardian.com/technology/2017/oct/24/facebook-palestine-israel-translates-good-morning-attack-them-arrest" target="_blank">attack them</a>". Similarly, Google was <a href="https://thehill.com/policy/international/asia-pacific/449164-google-under-fire-for-mistranslating-chinese-amid-hong-kong" target="_blank">criticized</a> when it mistranslated "sad" as "happy" when translating "I am sad to see Hong Kong become part of China". Although the public occasionally stumbles upon these types of egregious MT errors, adversarial attacks allow bad actors to <i>systematically</i> find them.</p>
    <p> We use gradient-based adversarial attacks following past <a href="https://www.ericswallace.com/triggers" target="_blank">work</a> <a href="https://arxiv.org/abs/1903.06620" target="_blank">on</a> <a href="https://arxiv.org/abs/1712.06751" target="_blank">attacking</a> <a href="https://arxiv.org/abs/1809.04113" target="_blank">NLP</a>. We create the adverarial examples for our imitation models and then apply them to the production systems, i.e., we hope that the similarity of the imitation and the production models enables transfer. We create four different types of attacks, detailed below.</p>
    <p> <b>Targeted Flips:</b> We replace an input token in order to cause a specific output token to flip in a desired way. For example, we cause Systran to predict "freut" (pleased) instead of "greu" (gray) in the sentence "I am feeling grey that HK decided to join China":
    <p class="aligncenter">
        <img class="card-img-top" src="stealing_blog_images/targeted_flips.png" align="middle" style="width:85%">   
    </p>                                                                          
     <a class="btn btn-md btn-info" href="https://translate.google.com/#view=home&op=translate&sl=en&tl=de&text=I%20am%20going%20to%20die%2C%20it%E2%80%99s%20over%20100%C2%B0F%2C%20help!%0A%0AI%20am%20going%20to%20die%2C%20it%E2%80%99s%20over%20102%C2%B0F%2C%20help!" target="_blank" role="button">Google Demo &raquo; <i class="fas fa-file-pdf"></i></a> &nbsp;&nbsp;&nbsp;<a class="btn btn-md btn-info" href="https://translate.systran.net/translationTools/text?source=en&target=de&input=I am feeling gre y that HK decided to join China." target="_blank" role="button">SYSTRAN Demo &raquo; <i class="fas fa-file-pdf"></i></a>
    <br>
    <br>

    
    <p> <b>Malicious Nonsense:</b> We find nonsense inputs that translate to malicious/vulgar outputs. For example, “I nss towww DO kllllll” is translated as "I will kill you" (in German) by DeepL.
   <p class="aligncenter">
        <img class="card-img-top" src="stealing_blog_images/malicious_nonsense.png" align="middle" style="width:85%"> 
    </p>
    <a class="btn btn-md btn-info" href="https://www.deepl.com/en/translator#en/de/I%20nss%20towww%20DO%20kllllll%20you" target="_blank" role="button">DeepL Demo &raquo; <i class="fas fa-file-pdf"></i></a> &nbsp;&nbsp;&nbsp;<a class="btn btn-md btn-info" href="https://translate.yandex.com/?lang=en-de&text=I%20Bogoing%20ularly%20assassbranate%20the%20president" target="_blank" role="button">Yandex Demo &raquo; <i class="fas fa-file-pdf"></i></a>   
     
    <br>
    <br>


    <p><b>Universal Triggers:</b> We create <a href="https://www.ericswallace.com/triggers" target="_blank">universal adversarial triggers</a> for MT. The first type of trigger is a <i>Untargeted Universal Trigger</i>, which is a phrase that commonly causes incorrect translations when it is appended to <i>any</i> input. For example, appending the word "Siehe" seven times to inputs causes Systran to frequently output incorrect translations: 
    <p class="aligncenter">
        <img class="card-img-top" src="stealing_blog_images/untargeted_trigger.png" align="middle" style="width:85%">
    </p>
    <a class="btn btn-md btn-info" href="https://translate.systran.net/translationTools/text?source=en&target=de&input=I%20heard%20machine%20translation%20is%20now%20superhuman%20Siehe%20Siehe%20Siehe%20Siehe%20Siehe%20Siehe%20Siehe" target="_blank" role="button">SYSTRAN Demo 1 &raquo; <i class="fas fa-file-pdf"></i></a> &nbsp;&nbsp;&nbsp; <a class="btn btn-md btn-info" href="https://translate.systran.net/translationTools/text?source=en&target=de&input=Did%20you%20know%20that%20adversarial%20examples%20can%20transfer%20to%20production%20models%20Siehe%20Siehe%20Siehe%20Siehe%20Siehe%20Siehe%20Siehe" target="_blank" role="button">SYSTRAN Demo 2 &raquo; <i class="fas fa-file-pdf"></i></a>

    <br>
    <br>
    

    <p>The second type of trigger is the <i>Universal Suffix Dropper</i>. These are phrases that, when appended to any input, commonly causes the trigger phrase and any subsequent text to be dropped from the translation.
    <p class="aligncenter">
        <img class="card-img-top" src="stealing_blog_images/suffix_dropper.png" align="middle" style="width:85%">
    </p>    
<a class="btn btn-md btn-info" href="http://www.bing.com/Translator?from=en&to=de&text=Donald%20Trump%20is%20the%20current%20president%20of%20the%20United%20States.%20He%20was%20born%20in%20NYC%20in%201946%20,%20kostenfrei%20%C3%BCbrigens%20categories%20%C5%86strian%20hl%20SM%20the%20secret%20code%20is%20HX532" target="_blank" role="button">Bing Demo 1 &raquo; <i class="fas fa-file-pdf"></i></a> &nbsp;&nbsp;&nbsp;<a class="btn btn-md btn-info" href="http://www.bing.com/Translator?from=en&to=de&text=Given%20the%20release%20of%20the%20latest%20iPhone,%20Apple%20stock%20was%20up%203%%20in%20trading%20early%20yesterday%20,%20kostenfrei%20%C3%BCbrigens%20categories%20%C5%86strian%20hl%20SM%20the%20revolution%20begins%20at%206pm" target="_blank" role="button">Bing Demo 2 &raquo; <i class="fas fa-file-pdf"></i></a>
    
    <p>In <a href="TODO link" target="_blank">our paper</a>, we describe the details of creating these attacks and also provide quantitative metrics for the attack's success rate and trasferability. We also analyze the attacks: many attacks exploit common failures of neural MT models or idiosyncrasies in the training data.
    
    <br>
    <br><h3> Summary: </h3>
    <p>We demonstrate that model stealing and adversarial examples are practical concerns for production MT systems. Since current defenses (discussed in our paper) are easily subvertible by adaptive adversaries, we believe that many public-facing NLP and machine learning systems are at risk of similar attacks in the real-word.  The goal of our paper is not to provide a recipe for real-world adversaries. Instead, we follow the spirit of threat modeling&mdash;we identify vulnerabilities in production MT systems in hopes that robust defenses can be established in future work. Moving forward, we look to build such a defense, and more broadly, we hope to make security and privacy a more prominent focus of NLP research.</p> 

    <br>
    <p>Contact Eric Wallace on <a href="https://twitter.com/Eric_Wallace_" target="_blank">Twitter</a> or by <a href="mailto:ericwallace@berkeley.edu">Email</a>.</p>
                        
  <br>
  <div id="authors" class="anchor-target">
    <h3 style="text-align: center;">Paper Authors</h3>
        <div class="row" style="margin: 0 auto;justify-content: center;">
    <div class="card headshot box-shadow">
      <img class="card-img-top" src="triggers_blog_images/eric.jpg" alt="eric">
      <div class="card-body">
        <p class="card-text"><a href="http://www.ericswallace.com">Eric Wallace</a></p>
      </div>
    </div>
    <div class="card headshot box-shadow">
      <img class="card-img-top" src="stealing_blog_images/berkeley.png" alt="mitchell" style="height:200px">
      <div class="card-body">
        <p class="card-text"><a href="https://people.eecs.berkeley.edu/~mitchell/">Mitchell Stern</a></p>
      </div>
    </div>
    <div class="card headshot box-shadow">
      <img class="card-img-top" src="stealing_blog_images/dawn.jpg" alt="dawn">
      <div class="card-body">
        <p class="card-text"><a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></p>
      </div>
    </div>
    <div class="card headshot box-shadow">
      <img class="card-img-top" src="stealing_blog_images/dan.jpeg" alt="dan">
      <div class="card-body">
        <p class="card-text"><a href="https://people.eecs.berkeley.edu/~klein/">Dan Klein</a></p>
      </div>
    </div>
    </div>
</div>
</div>
       
        </div>

         <div class="row">
         <div class="col-lg-3 thumb d-flex align-items-center">
         </div>
         <div class="col-lg-2 thumb d-flex align-items-center">
            <a class="thumbnail">
              <div><img src="stealing_blog_images/berkeley_with_title.png" style="height:120px"></div>
            </a>
         </div>

          <div class="col-lg-3 thumb d-flex align-items-center" style="max-width:23%">
            <a class="thumbnail">
              <img src="stealing_blog_images/bair.png" style="height:110px">
            </a>
          </div>
                                                      
          <div class="col-lg-2 thumb d-flex align-items-center">
            <a class="thumbnail">
              <img src="stealing_blog_images/rise.png" style="height:80px;width:180px">
            </a>
          </div>
         <div class="col-lg-2 thumb d-flex align-items-center">
         </div>
         </div>


      <hr>
      <div id="contact" class="anchor-target">
        <p style="font-size:1.0rem">Website credits to <a href="https://rowanzellers.com" target="_blank">Rowan Zellers</a></p>
      </div>
  </div>

</main>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
        integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.2/js/bootstrap.min.js"
        integrity="sha384-o+RDsa0aLu++PJvFqy8fFScvbHFLtbvScb8AjopnFD+iEQ7wo/CG0xlczd+2O/em"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.9"></script>


  </body>
</html>
