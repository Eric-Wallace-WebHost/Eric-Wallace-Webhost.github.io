

<!DOCTYPE html>

<html>
<head>
	<meta charset="utf-8" />
	<title>Eric Wallace&mdash; Home</title>
	<link rel="stylesheet" href="master.css" />

	<link href="https://fonts.googleapis.com/css?family=Roboto+Slab:300,400,700" rel="stylesheet">

	<script>
	    function unhide(divID) {
	        var item = document.getElementById(divID);
	        if (item) {
	            item.className=(item.className=='hidden')?'unhidden':'hidden';
	        }
	}
	</script>

	<script type="text/javascript">
		var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
		document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
	</script>	
</head>

<body>
<div class="wrapper">

	<div class="posts-wrapper">
		<div class="post">
			<img src='crop.jpg' style="float:right; width:250px;"/>

			<h1>Eric Wallace</h1>

			<h2>ewallac2@umd.edu // <a href="/publications"> Publications</a> // <a href="https://github.com/Eric-Wallace-WebHost/Eric-Wallace-Webhost.github.io/raw/master/Eric%20Wallace%20Resume.pdf"> Resume</a> // <a href="https://linkedin.com/in/ericswallace"> LinkedIn</a> // <a href="https://www.github.com/Eric-Wallace">GitHub</a></h2>
			<br>

			<br>

			<p>I am a student at the University of Maryland working at the intersection of Deep Learning and Natural Language Processing. I am advised by <a href="http://www.umiacs.umd.edu/~jbg/">Jordan Boyd-Graber</a> and a member of the <a href="https://wiki.umiacs.umd.edu/clip/index.php/People">Computational Linguistics and Information Processing Lab</a>. 
			<br> <br>
	  		
	  		My broad research interest is in learning representations from raw data (text, video, audio) to solve problems in Language Understanding and Robotics. Recently, I have been focused on developing <i>robust</i>, <i>customizable</i>, and <i>interpretable</i> systems for language. I am excited about techniques in adversarial learning, meta-learning, and generative modeling. <br> <br>
			
			Previously I conducted research in GPU Computing and Computational Aerodynamics at the <a href="http://www.agrc.umd.edu/"> Alfred Gessow Rotorcraft Center</a> underneath <a href="https://sites.google.com/site/apnpun/home"> Ananth Sridharan</a> and <a href="http://inderjitchopra.umd.edu/"> Inderjit Chopra</a>. I interned at Lyft Self Driving in Summer 2018 and was an intern at Intel in Fall 2017. 

	        </p>
	        <br>
	    </div>
	</div>

	<div class="posts-wrapper">
		<div class="post">
			<ul class="news">
			<li><strong>May. 2018: </strong>Joining Lyft Self Driving as an intern this Summer in Palo Alto, CA</li>
			<li><strong>May. 2018: </strong>Paper accepted at ACL Student Research Workshop</li>
			<li><strong>Jan. 2018: </strong>Presented work on GPU parallelization at 2018 AIAA Scitech in Orlando</li>
			<li><strong>Nov. 2017: </strong>Talk at Google DeepMind Starcraft 2 AI Workshop in Anaheim, California</li>
			<li><strong>May. 2017: </strong>Talk for Aerospace Board of Advisors at the University of Maryland</li>
			<li><strong>Apr. 2017: </strong>Won Best Paper at the AIAA Student Conference hosted by the University of Virginia</li>
			</ul>

		</div>
	</div>
	<br><br>

	<div class="posts-wrapper" style="clear:both">
		<h3 style="margin-bottom:0.75em;">active projects</h3>
		</i>
		<p>
		<i>Robustness in Deep Natural Language Processing</i><br>
		<!-- <img src='strong.png' align='left' style="width:125px;height:110px"/> -->
		Models deployed "in the wild" often face data distributions unlike those seen during training. How can language systems be safe against adversaries looking to exploit them? Even when adversaries aren't present, how can models handle noise from users and upstream language systems (ASR, MT)? <!-- We are currently exploring ideas in defending against adversaries and , adapting to domain shift, handling rare words, and normalizing text in an end-to-end manner. -->
		</p>	
 
		<p>
		<i>Adapting Language Systems to New Domains</i><br>
		<!-- <i>Current: Amr Sharaf, Shi Feng, <b>Eric Wallace</b>, Jordan Boyd-Graber, Hal Daumé III, and others <br></i> -->
<!-- 		<img src='data/idea.png' align='left' style="width:120px"/> -->

		There isn't sufficient data to train models in every domain we care about. Instead, how can we adapt existing systems to each specific use case with only a small amount of data? Furthermore, how can we create powerful machine learning systems for low resource languages?<br>
		</p>

		<p>
		<i>Interpretable Language Systems</i><br>
		<!-- <i>Current: Shi Feng, <b>Eric Wallace</b>, Jordan Boyd-Graber, and others <br></i> -->
		<!-- <img src='data/idea.png' align='left' style="width:120px"/> -->
		It is crucial to know why models make the decisions they do (at the very least, for debugging). Specifically, which training data points are the most influential for a model's decision? Alternatively, which features of a test input are most impactful for the observed output?
		<br>
		</p>

		<i>Fantastic Collaborators: Shi Feng, Amr Sharaf, Pedro Rodriguez, Mohit Iyyer, Jordan Boyd-Graber, Hal Daumé III, and others</i>
		<p><a href="https://people.cs.umass.edu/~miyyer/">Mohit makes great websites</a></p> 

</div>
</div>



</body>
</html>
