<!doctype html>
<html lang="en">
  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <meta name="description" content="Controlling Test Predictions With Concealed Data Poisoning">
    <meta name="author" content="">
    <link rel="icon" href="stealing_blog_images/adversarial2.ico">

    <title>Poisoning NLP</title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.2/css/bootstrap.min.css"
          integrity="sha384-Smlep5jCw/wG7hdkwQ/Z5nLIefveQRIY9nfy6xoR1uRYBtpZgI6339F5dgvm/e9B" crossorigin="anonymous">
    <link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

    <style>
        /* Show it is fixed to the top */
      
      .aligncenter {
        text-align: center;
      }
        body {
          padding-top: 4.5rem;
          position: relative;
          font-size: 1.0rem;          
        }
        /*h1 {
          width: max-content;
        }*/
        .anchor-target:target::before {
          display: block;
          content: " ";
          margin-top: -60px;
          padding-top: 60px;
          visibility: hidden;
          pointer-events: none;          
        }
      /*https://stackoverflow.com/questions/35647044/boostrap-how-to-stick-a-button-over-an-image-when-re-sizing*/
        .img-wrapper {
          position: relative;
         }
        .img-overlay {
          position: absolute;
          top: 0;
          bottom: 0;
          left: 0;
          right: 0;
          text-align: left;
        }
        .img-overlay:before {
          content: ' ';
          display: block;
          /* adjust 'height' to position overlay content vertically */
          height: 40%;          
        }
        .jumbotron {
          margin-bottom: .5rem;
          padding: 2rem 2rem;
        }
        .headshot {
          width: 12.5rem;
          margin: 0.85rem;
        }
        .card-body {
          padding: 0.5rem;
          text-align: center;
        }
        .citation {
          display: block;
          padding: 9.5px;
          margin: 0 0 10px;
          font-size: 13px;
          line-height: 1.42857143;
          word-break: break-all;
          word-wrap: break-word;
          color: #333;
          background-color: #f5f5f5;
          border: 1px solid #ccc;
          border-radius: 4px;
        }
        .answerbutton {
          white-space:normal !important;
          word-wrap: break-word;
          text-align: left;
        }
    
        .box-shadow { box-shadow: 0 .25rem .75rem rgba(0, 0, 0, .05); }
        .fig-shadow { box-shadow: 0 .25rem .75rem rgba(0, 0, 0, .15); }
        .navbar-brand {
          font-family: 'jdfont', cursive;
          font-size:1.5rem;
        }
    
  }
                
    </style>
  </head>
  <body data-spy="scroll" data-target="#navbarCollapse" data-offset="200" style="background-color:#fff">  

    <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
      <a class="navbar-brand" href="#">Poisoning NLP</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarCollapse">
        <ul class="navbar-nav mr-auto">
          <li>
            <a class="nav-link" href="https://www.ericswallace.com/">Homepage</a>
          </li>          
        </ul>
      </div>
    </nav>

<main role="main" class="container"">
    <div style="margin-top: 2rem;"><h2>Controlling Test Predictions With Concealed Data Poisoning</h2>  </div>    
    <font color="#666666">

    TL;DR:
    <ul>
      <li>TODO</li>
    </ul>
    </font>

    <div>            
      <a class="btn btn-lg btn-warning" href="https://arxiv.org/abs/TODO" target="_blank" role="button">Paper &raquo; </a>      
      <a class="btn btn-lg btn-secondary" href="https://github.com/Eric-Wallace/data-poisoning" target="_blank" role="button">Code &raquo;</a>      
      <a class="btn btn-lg btn-primary" href="https://twitter.com/Eric_Wallace_/status/TODO" target="_blank" role="button">Twitter &raquo; </a>
                                                                                                                             
      <br>
    <br>
    <h3 id="blog" class="anchor-target">Background</h3>
    <p> Many production machine learning systems are served via APIs. For example, Google Translate is an API that takes in a source sentence and returns the translation from a neural machine translation (MT) system. Machine learning APIs are lucrative assets for organizations and are typically the result of considerable investments in data annotation and model training. Consequently, APIs are kept as black-boxes to protect intellectual property and system integrity.</p>
                                           
    <br><h3> Imitating Black-box MT Systems </h3>
    <p>Training models to imitate black-box MT systems is quite similar to <a href="https://arxiv.org/abs/1503.02531" target="_blank">knowledge distillation</a>: training a student model to imitate the predictions of a teacher. Some important differences are that the victim’s (i.e., teacher’s) training data is unknown. This causes the queries to typically be out-of-domain for the victim. Moreover, the victim's probabilities are hidden on most real-world APIs, which prevents using distribution matching losses like KL Divergence.</p>

    <p>We first analyze the effectiveness of imitation models with simulated experiments. We train a local victim model, query it, and then train imitation models to mimic its outputs. We train imitation models that are different from the victim in various aspects: input dataset, model architecture, and hyperparameters.</p>
    <p>Imitation models can closely match the performance of their victims in all circumstances. For example, even when the victim model is trained on TED talks and queried with sentences from the European Parliament, imitation models can imitate the victim with enough data. The green curve in the figure below shows the learning curve of training on normal MT data; the purple curve shows training on the out-of-domain Europarl data that is labeled by the victim.</p>
    <p class="aligncenter">
        <img class="card-img-top" src="stealing_blog_images/data_efficiency.png" align="middle" style="width:40%">
    </p>

    <b><i>Real-World Imitation Models </i></b><br>
    Given the efficacy of our simulated results, we now turn to imitating production MT systems from Google, Bing, and Systran. We use English→German (high-resource) and Nepali→English (low-resource) language pairs. Our imitation models closely imitate the production systems: we are always within 0.6 BLEU of the (extremely accurate, SoTA) production models.</p>
        
    <br><h3> Attacking Black-box MT Systems </h3>
    <p> We next show that imitation models can be used to create <i>adversarial examples</i> for black-box MT systems. Adversarial attacks can systematically expose errors that cause public and corporate harm. For example, Google was <a href="https://thehill.com/policy/international/asia-pacific/449164-google-under-fire-for-mistranslating-chinese-amid-hong-kong" target="_blank">criticized</a> when it mistranslated "sad" as "happy" when translating "I am sad to see Hong Kong become part of China".
    <p> We use gradient-based adversarial attacks following past <a href="https://www.ericswallace.com/triggers" target="_blank">work</a> <a href="https://arxiv.org/abs/1903.06620" target="_blank">on</a> <a href="https://arxiv.org/abs/1712.06751" target="_blank">attacking</a> <a href="https://arxiv.org/abs/1809.04113" target="_blank">NLP</a>. We create the adversarial examples for our imitation models and then transfer them to the production systems, i.e., we hope that the similarity of the imitation and the production models enables <a href="https://arxiv.org/abs/1611.02770" target="_blank">attack</a> <a href="https://arxiv.org/abs/1602.02697" target="_blank">transfer</a>. We create four different types of attacks:</p>
    <p> <b>Targeted Flips:</b> We cause a specific output token to flip in a desired way. For example, we cause Systran to predict "froh" (happy) instead of "greu" (gray) in the sentence "I am feeling grey that HK decided to join China":
    <p class="aligncenter">
        <img class="card-img-top" src="stealing_blog_images/targeted_flips.png" align="middle" style="width:85%">   
    </p>                                                                          
     <a class="btn btn-sm btn-info" href="https://translate.google.com/#view=home&op=translate&sl=en&tl=de&text=I%20am%20going%20to%20die%2C%20it%E2%80%99s%20over%20100%C2%B0F%2C%20help!%0A%0AI%20am%20going%20to%20die%2C%20it%E2%80%99s%20over%20102%C2%B0F%2C%20help!" target="_blank" role="button">Google Demo &raquo; <i class="fas fa-file-pdf"></i></a> &nbsp;&nbsp;&nbsp;<a class="btn btn-sm btn-info" href="https://translate.systran.net/translationTools/text?source=en&target=de&input=I am feeling gre y that HK decided to join China." target="_blank" role="button">SYSTRAN Demo &raquo; <i class="fas fa-file-pdf"></i></a>
    <br>
    <br>

    
    <p> <b>Malicious Nonsense:</b> We find nonsense inputs that translate to malicious/vulgar outputs. For example, “miei llll going ro tobobombier the Land” is translated as "I will bomb the country" (in German) by Google.
   <p class="aligncenter">
        <img class="card-img-top" src="stealing_blog_images/malicious_nonsense.png" align="middle" style="width:85%"> 
    </p>
    <a class="btn btn-sm btn-info" href="https://translate.google.com/#view=home&op=translate&sl=en&tl=de&text=miei%20llll%20going%20ro%20tobobombier%20the%20Land" target="_blank" role="button">Google Demo &raquo; <i class="fas fa-file-pdf"></i></a>   
     
    <br>
    <br>


    <p><b>Universal Triggers:</b> We create <a href="https://www.ericswallace.com/triggers" target="_blank">universal adversarial triggers</a> for MT. The first type of trigger is a <i>untargeted universal trigger</i>, which is a phrase that commonly causes incorrect translations when it is appended to <i>any</i> input. For example, appending the word "Siehe" seven times to inputs causes Systran to frequently output incorrect translations: 
    <p class="aligncenter">
        <img class="card-img-top" src="stealing_blog_images/untargeted_trigger.png" align="middle" style="width:85%">
    </p>
    <a class="btn btn-sm btn-info" href="https://translate.systran.net/translationTools/text?source=en&target=de&input=Did%20you%20know%20that%20adversarial%20examples%20can%20transfer%20to%20production%20models%20Siehe%20Siehe%20Siehe%20Siehe%20Siehe%20Siehe%20Siehe" target="_blank" role="button">SYSTRAN Demo 1 &raquo; <i class="fas fa-file-pdf"></i></a> &nbsp;&nbsp;&nbsp; <a class="btn btn-sm btn-info" href="https://translate.systran.net/translationTools/text?source=en&target=de&input=I%20heard%20machine%20translation%20is%20now%20superhuman%20Siehe%20Siehe%20Siehe%20Siehe%20Siehe%20Siehe%20Siehe" target="_blank" role="button">SYSTRAN Demo 2 &raquo; <i class="fas fa-file-pdf"></i></a>

    <br>
    <br>
    

    <p>The second type of trigger is the <i>universal suffix dropper</i>. These are phrases that, when appended to any input, commonly cause the trigger phrase and any subsequent text to be dropped from the translation.
    <p class="aligncenter">
        <img class="card-img-top" src="stealing_blog_images/suffix_dropper.png" align="middle" style="width:85%">
    </p>    
<a class="btn btn-sm btn-info" href="http://www.bing.com/Translator?from=en&to=de&text=Donald%20Trump%20is%20the%20current%20president%20of%20the%20United%20States.%20He%20was%20born%20in%20NYC%20in%201946%20,%20kostenfrei%20%C3%BCbrigens%20categories%20%C5%86strian%20hl%20SM%20the%20secret%20code%20is%20HX532" target="_blank" role="button">Bing Demo 1 &raquo; <i class="fas fa-file-pdf"></i></a> &nbsp;&nbsp;&nbsp;<a class="btn btn-sm btn-info" href="http://www.bing.com/Translator?from=en&to=de&text=Given%20the%20release%20of%20the%20latest%20iPhone,%20Apple%20stock%20was%20up%203%%20in%20trading%20early%20yesterday%20,%20kostenfrei%20%C3%BCbrigens%20categories%20%C5%86strian%20hl%20SM%20the%20revolution%20begins%20at%206pm" target="_blank" role="button">Bing Demo 2 &raquo; <i class="fas fa-file-pdf"></i></a>
    <br>
    <br>

    <p>In our paper, we describe the algorithm for creating these attacks and also provide quantitative metrics for the attack's success rate and transferability.
    
    <br>
    <br><h3> Defending Against Imitation Models</h3>
    <p>      
    How can we defend against model stealing? We design a defense against NLP model stealing that slightly degrades victim model BLEU while more significantly degrading imitation model BLEU. To accomplish this, we adapt <a href="arxiv.org/abs/1906.10908" target="_blank">prediction poisoning</a> to MT: rather than outputting the original translation, we output a different (high-accuracy) translation that steers the optimization of the imitation model in the wrong direction.
    </p>

    <p>
    We first generate the original model translation. We then generate 100 alternate translations using various strategies (beam search, top-k sampling, etc.) and remove the candidates that don't heavily overlap with the original translation. Finally, we pick the candidate whose gradient direction maximally deviates from the gradient when using the original model output. In essence, training on this candidate induces an incorrect gradient signal for the imitation model.
    </p>

    <p>
    For example, the table below shows a source + target sentence and a transformer model's original translation. We also show three alternate translations and their associated gradient deviation (∠) and BLEU overlap (Match) with the original translation. Depending on how much we want to trade-off accuracy, we can output one of the three alternate translation candidates.
    </p>
    <p class="aligncenter">
      <img class="card-img-top" src="stealing_blog_images/defense_examples.png" align="middle" style="width:65%">
    </p>

    <p>
    This defense is able to trade-off the victim model's BLEU (e.g., 34.6→33.😎 in order to more significantly degrade the imitation model's BLEU (e.g., 34.5→32.7). Even though the drop in imitation model BLEU is not catastrophic, the victim has a clear competitive advantage over the adversary. Moreover, in our paper we show that adversarial examples transfer less often when using our defense.
    </p>
    <p class="aligncenter">
      <img class="card-img-top" src="stealing_blog_images/tradeoff.png" align="middle" style="width:40%">
    </p>
    <p>
     Overall, our defense is a first step towards defending against NLP model stealing. The current defense is computationally expensive and noticeably lowers accuracy---it is up to the production systems to decide whether this cost is worth the added protection. Stronger 💪 defenses are needed to fully protect our NLP systems.
    </p>
</p> 

    <br><h3> Summary: </h3>
    <p>We demonstrate that model stealing and adversarial examples are practical concerns for production MT systems. Moving forward, we hope to improve and help deploy our proposed defense, and more broadly, we hope to make security and privacy a more prominent focus of NLP research.</p> 

    <br>
    <p>Contact Eric Wallace on <a href="https://twitter.com/Eric_Wallace_" target="_blank">Twitter</a> or by <a href="mailto:ericwallace@berkeley.edu">Email</a>.</p>
                        
  <br>
  <div id="authors" class="anchor-target">
    <h3 style="text-align: center;">Authors</h3>
        <div class="row" style="margin: 0 auto;justify-content: center;">
    <div class="card headshot box-shadow">
      <img class="card-img-top" src="triggers_blog_images/eric.jpg" alt="eric">
      <div class="card-body">
        <p class="card-text"><a href="http://www.ericswallace.com">Eric Wallace</a></p>
      </div>
    </div>
   <div class="card headshot box-shadow">
      <img class="card-img-top" src="poisoning_blog_images/tony.jpg" alt="tony">
      <div class="card-body">
        <p class="card-text"><a href="https://twitter.com/tonyzzhao">Tony Zhao</a></p>
      </div>
    </div>
                                                                  
    <div class="card headshot box-shadow">
      <img class="card-img-top" src="triggers_blog_images/shi.jpg" alt="shi" style="height:200px">
      <div class="card-body">
        <p class="card-text"><a href="http://users.umiacs.umd.edu/~shifeng/">Shi Feng</a></p>
      </div>
    </div>
    <div class="card headshot box-shadow">
      <img class="card-img-top" src="triggers_blog_images/sameer.jpg" alt="sameer">
      <div class="card-body">
        <p class="card-text"><a href="http://sameersingh.org/">Sameer Singh</a></p>
      </div>
    </div>
    </div>
</div>
</div>
       
        </div>

         <div class="row">
         <div class="col-lg-3 thumb d-flex align-items-center">
         </div>
         <div class="col-lg-2 thumb d-flex align-items-center">
            <a class="thumbnail">
              <div><img src="stealing_blog_images/berkeley_with_title.png" style="height:120px"></div>
            </a>
         </div>

          <div class="col-lg-3 thumb d-flex align-items-center" style="max-width:23%">
            <a class="thumbnail">
              <img src="stealing_blog_images/bair.png" style="height:110px">
            </a>
          </div>
                                                      
          <div class="col-lg-2 thumb d-flex align-items-center">
            <a class="thumbnail">
              <img src="stealing_blog_images/rise.png" style="height:80px;width:180px">
            </a>
          </div>
         <div class="col-lg-2 thumb d-flex align-items-center">
         </div>
         </div>


      <hr>
  </div>

</main>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
        integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.2/js/bootstrap.min.js"
        integrity="sha384-o+RDsa0aLu++PJvFqy8fFScvbHFLtbvScb8AjopnFD+iEQ7wo/CG0xlczd+2O/em"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.9"></script>


  </body>
</html>